Ollama has advantages for prompting a knowledge base offline but at times can get very slow. It takes too long for it to be useful in a chatbot app.

Response time average per model:

- llama-3-405b: 30 seconds
- mistral-nemo: > 4 minutes